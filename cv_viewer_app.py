import os
import pandas as pd
import streamlit as st
import fitz  # PyMuPDF
from docx import Document
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import sqlite3
from datetime import datetime

# --- ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ---
df_train = pd.read_csv("training_data.csv")
vectorizer = TfidfVectorizer(stop_words='english')
X = vectorizer.fit_transform(df_train["Resume_Text"])
y = df_train["Match"]
model = LogisticRegression(class_weight='balanced')
model.fit(X, y)

# --- ØªØ¹Ø±ÙŠÙ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙˆØ¸Ø§Ø¦Ù ---
job_groups = {
    "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª": ["Data Analyst", "Business Analyst", "Reporting Analyst"],
    "ØªØ·ÙˆÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§Øª": ["Software Developer", "Backend Engineer", "Full Stack Developer"],
    "Ø¯Ø¹Ù… ÙÙ†ÙŠ": ["IT Support", "Helpdesk", "Technical Support"],
    "Ù‡Ù†Ø¯Ø³Ø© Ù†Ø¸Ù…": ["Systems Engineer", "Infrastructure Engineer", "DevOps"],
    "Ø¥Ø¯Ø§Ø±Ø© Ù…Ø´Ø§Ø±ÙŠØ¹": ["Project Manager", "Project Coordinator", "Scrum Master"],
    "ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªØ£Ù…ÙŠÙ†": ["Insurance Specialist", "Insurance Analyst", "Underwriter", "Claims Processor", "Insurance Coordinator"]
}

# --- ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ---
df = pd.read_excel("batch_prediction_by_city.xlsx")

st.title("ğŸ“‹ Ù„ÙˆØ­Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ©")

# --- Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© ÙˆØ§Ù„ÙˆØ¸ÙŠÙØ© ---
cities = sorted(df["City"].dropna().unique())
selected_city = st.selectbox("ğŸ™ï¸ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", cities)

selected_job_group = st.selectbox("ğŸ§³ Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ÙˆØ¸ÙŠÙØ©", list(job_groups.keys()))
related_titles = job_groups[selected_job_group]

# --- ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¹Ø±Ø¶Ù‡Ø§ ---
filtered_df = df[
    (df["City"] == selected_city) &
    (df["Job_Title"].isin(related_titles))
]

st.write(f"ğŸ” Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {len(filtered_df)}")
st.dataframe(filtered_df)

# --- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ€ Excel ---
from io import BytesIO
output = BytesIO()
with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
    filtered_df.to_excel(writer, index=False, sheet_name='Resumes')
output.seek(0)

st.download_button(
    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ€ Excel",
    data=output,
    file_name=f"{selected_city}_{selected_job_group}_resumes.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

# --- Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ®Ø²ÙŠÙ† ---
conn = sqlite3.connect("cv_results.db", check_same_thread=False)
cursor = conn.cursor()
cursor.execute('''
    CREATE TABLE IF NOT EXISTS resumes (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        file_name TEXT,
        city TEXT,
        job_group TEXT,
        result TEXT,
        timestamp TEXT
    )
''')
conn.commit()

# --- Ø±ÙØ¹ ÙˆØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ±Ø© Ø¬Ø¯ÙŠØ¯Ø© ---
st.header("ğŸ“¤ ØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© (PDF Ø£Ùˆ Word)", type=["pdf", "docx"])

def extract_text(file):
    if file.name.endswith(".pdf"):
        text = ""
        with fitz.open(stream=file.read(), filetype="pdf") as doc:
            for page in doc:
                text += page.get_text()
        return text
    elif file.name.endswith(".docx"):
        doc = Document(file)
        return "\n".join([para.text for para in doc.paragraphs])
    return None

if uploaded_file:
    st.info(f"ğŸ“„ ØªÙ… Ø±ÙØ¹: {uploaded_file.name}")
    resume_text = extract_text(uploaded_file)

    if resume_text:
        vector = vectorizer.transform([resume_text])
        prediction = model.predict(vector)[0]
        result = "âœ… Ù…Ù†Ø§Ø³Ø¨" if prediction == 1 else "âŒ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨"
        st.success(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {result}")

        # --- Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
        cursor.execute('''
            INSERT INTO resumes (file_name, city, job_group, result, timestamp)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            uploaded_file.name,
            selected_city,
            selected_job_group,
            result,
            datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ))
        conn.commit()
        st.info("ğŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
    else:
        st.warning("âš ï¸ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù.")

# --- Ù„ÙˆØ­Ø© Ø¹Ø±Ø¶ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
st.header("ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")

df_db = pd.read_sql_query("SELECT * FROM resumes ORDER BY timestamp DESC", conn)
st.dataframe(df_db)
